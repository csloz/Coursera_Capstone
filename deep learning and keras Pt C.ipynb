{
    "cells": [
        {
            "cell_type": "markdown",
            "source": [
                "# Keras Project B\n",
                "\n",
                "\n",
                "### Lawrence Sheed*\n",
                "\n",
                "---\n"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "source": [
                "#Disable pip's annoying warnings\n",
                "%env _PIP_LOCATIONS_NO_WARN_ON_MISMATCH=1 \n",
                "\n",
                "#disable python warnings\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "warnings.simplefilter('ignore')\n",
                "\n",
                "#install libraries needed\n",
                "!pip install pandas\n",
                "!pip install numpy\n",
                "!pip install keras\n",
                "!pip install tensorflow\n",
                "!pip install scikit-learn\n",
                "\n",
                "import pandas as pd # library for data analysis\n",
                "import numpy as np # library to handle data in a vectorized manner\n",
                "import keras\n",
                "import tensorflow\n",
                "import sklearn.metrics\n",
                "\n",
                "from keras.models import Sequential\n",
                "from keras.layers import Dense\n",
                "from sklearn.metrics import mean_squared_error\n",
                "from IPython.display import display_html\n",
                "\n",
                "print('Libraries imported.')\n",
                "\n",
                "pd.set_option('display.max_columns', None)\n",
                "pd.set_option('display.max_rows', None)\n",
                "\n"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "env: _PIP_LOCATIONS_NO_WARN_ON_MISMATCH=1\n",
                        "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\n",
                        "Requirement already satisfied: pandas in /usr/local/lib/python3.9/site-packages (1.3.1)\n",
                        "Requirement already satisfied: python-dateutil>=2.7.3 in /Users/lawrence/Library/Python/3.9/lib/python/site-packages (from pandas) (2.8.2)\n",
                        "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.9/site-packages (from pandas) (1.19.5)\n",
                        "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.9/site-packages (from pandas) (2021.1)\n",
                        "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
                        "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\n",
                        "Requirement already satisfied: numpy in /usr/local/lib/python3.9/site-packages (1.19.5)\n",
                        "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\n",
                        "Requirement already satisfied: keras in /usr/local/lib/python3.9/site-packages (2.4.3)\n",
                        "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.9/site-packages (from keras) (1.19.5)\n",
                        "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.9/site-packages (from keras) (1.7.0)\n",
                        "Requirement already satisfied: h5py in /usr/local/lib/python3.9/site-packages (from keras) (3.1.0)\n",
                        "Requirement already satisfied: pyyaml in /usr/local/lib/python3.9/site-packages (from keras) (5.4.1)\n",
                        "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\n",
                        "Requirement already satisfied: tensorflow in /usr/local/lib/python3.9/site-packages (2.5.0)\n",
                        "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.9/site-packages (from tensorflow) (0.13.0)\n",
                        "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.9/site-packages (from tensorflow) (1.1.0)\n",
                        "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.9/site-packages (from tensorflow) (1.12.1)\n",
                        "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.9/site-packages (from tensorflow) (0.36.2)\n",
                        "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.9/site-packages (from tensorflow) (1.12)\n",
                        "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.9/site-packages (from tensorflow) (1.1.2)\n",
                        "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.9/site-packages (from tensorflow) (3.7.4.3)\n",
                        "Requirement already satisfied: tensorflow-estimator<2.6.0,>=2.5.0rc0 in /usr/local/lib/python3.9/site-packages (from tensorflow) (2.5.0)\n",
                        "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.9/site-packages (from tensorflow) (1.6.3)\n",
                        "Requirement already satisfied: keras-nightly~=2.5.0.dev in /usr/local/lib/python3.9/site-packages (from tensorflow) (2.5.0.dev2021032900)\n",
                        "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.9/site-packages (from tensorflow) (3.3.0)\n",
                        "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.9/site-packages (from tensorflow) (0.4.0)\n",
                        "Requirement already satisfied: grpcio~=1.34.0 in /usr/local/lib/python3.9/site-packages (from tensorflow) (1.34.1)\n",
                        "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.9/site-packages (from tensorflow) (3.17.3)\n",
                        "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.9/site-packages (from tensorflow) (1.15.0)\n",
                        "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.9/site-packages (from tensorflow) (1.19.5)\n",
                        "Requirement already satisfied: tensorboard~=2.5 in /usr/local/lib/python3.9/site-packages (from tensorflow) (2.5.0)\n",
                        "Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.9/site-packages (from tensorflow) (3.1.0)\n",
                        "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.9/site-packages (from tensorflow) (0.2.0)\n",
                        "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.9/site-packages (from tensorboard~=2.5->tensorflow) (0.4.5)\n",
                        "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.9/site-packages (from tensorboard~=2.5->tensorflow) (3.3.4)\n",
                        "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.9/site-packages (from tensorboard~=2.5->tensorflow) (1.8.0)\n",
                        "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.9/site-packages (from tensorboard~=2.5->tensorflow) (1.34.0)\n",
                        "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.9/site-packages (from tensorboard~=2.5->tensorflow) (2.0.1)\n",
                        "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.9/site-packages (from tensorboard~=2.5->tensorflow) (0.6.1)\n",
                        "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.9/site-packages (from tensorboard~=2.5->tensorflow) (2.26.0)\n",
                        "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.9/site-packages (from tensorboard~=2.5->tensorflow) (57.0.0)\n",
                        "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (4.7.2)\n",
                        "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (0.2.8)\n",
                        "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.9/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (4.2.2)\n",
                        "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.9/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow) (1.3.0)\n",
                        "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (0.4.8)\n",
                        "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (3.2)\n",
                        "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (2.0.3)\n",
                        "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (1.26.6)\n",
                        "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (2021.5.30)\n",
                        "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow) (3.1.1)\n",
                        "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\n",
                        "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.9/site-packages (0.24.2)\n",
                        "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.9/site-packages (from scikit-learn) (1.19.5)\n",
                        "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/site-packages (from scikit-learn) (2.2.0)\n",
                        "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.9/site-packages (from scikit-learn) (1.0.1)\n",
                        "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.9/site-packages (from scikit-learn) (1.7.0)\n",
                        "Libraries imported.\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Get Data"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "source": [
                "concrete_data = pd.read_csv('https://cocl.us/concrete_data')\n",
                "display_html(concrete_data.head())\n",
                "\n",
                "\n"
            ],
            "outputs": [
                {
                    "output_type": "display_data",
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>Cement</th>\n",
                            "      <th>Blast Furnace Slag</th>\n",
                            "      <th>Fly Ash</th>\n",
                            "      <th>Water</th>\n",
                            "      <th>Superplasticizer</th>\n",
                            "      <th>Coarse Aggregate</th>\n",
                            "      <th>Fine Aggregate</th>\n",
                            "      <th>Age</th>\n",
                            "      <th>Strength</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>540.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>162.0</td>\n",
                            "      <td>2.5</td>\n",
                            "      <td>1040.0</td>\n",
                            "      <td>676.0</td>\n",
                            "      <td>28</td>\n",
                            "      <td>79.99</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>540.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>162.0</td>\n",
                            "      <td>2.5</td>\n",
                            "      <td>1055.0</td>\n",
                            "      <td>676.0</td>\n",
                            "      <td>28</td>\n",
                            "      <td>61.89</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>332.5</td>\n",
                            "      <td>142.5</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>228.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>932.0</td>\n",
                            "      <td>594.0</td>\n",
                            "      <td>270</td>\n",
                            "      <td>40.27</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>332.5</td>\n",
                            "      <td>142.5</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>228.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>932.0</td>\n",
                            "      <td>594.0</td>\n",
                            "      <td>365</td>\n",
                            "      <td>41.05</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>198.6</td>\n",
                            "      <td>132.4</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>192.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>978.4</td>\n",
                            "      <td>825.5</td>\n",
                            "      <td>360</td>\n",
                            "      <td>44.30</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ]
                    },
                    "metadata": {}
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Clean data"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "source": [
                "\n",
                "print (\"How many data points?\")\n",
                "print(concrete_data.shape)\n",
                "print (\"Describe data\")\n",
                "display_html(concrete_data.describe())\n",
                "print (\"Any null data to clean? (nope!)\")\n",
                "print(concrete_data.isnull().sum())\n",
                "\n",
                "#use strength column\n",
                "concrete_data_columns = concrete_data.columns\n",
                "predictors = concrete_data[concrete_data_columns[concrete_data_columns !='Strength']] \n",
                "target = concrete_data['Strength'] \n",
                "\n",
                "#check predictors and target\n",
                "print (\"Check predictors\")\n",
                "display_html(predictors.head())\n",
                "print (\"Check target\")\n",
                "display_html(target.head())\n",
                "\n",
                "print (\"Only 1 predictor - Strength\")\n",
                "cols = predictors.shape[1] # number of predictors\n",
                "print (\"Cols: \" + str(cols))\n"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "How many data points?\n",
                        "(1030, 9)\n",
                        "Describe data\n"
                    ]
                },
                {
                    "output_type": "display_data",
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>Cement</th>\n",
                            "      <th>Blast Furnace Slag</th>\n",
                            "      <th>Fly Ash</th>\n",
                            "      <th>Water</th>\n",
                            "      <th>Superplasticizer</th>\n",
                            "      <th>Coarse Aggregate</th>\n",
                            "      <th>Fine Aggregate</th>\n",
                            "      <th>Age</th>\n",
                            "      <th>Strength</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>count</th>\n",
                            "      <td>1030.000000</td>\n",
                            "      <td>1030.000000</td>\n",
                            "      <td>1030.000000</td>\n",
                            "      <td>1030.000000</td>\n",
                            "      <td>1030.000000</td>\n",
                            "      <td>1030.000000</td>\n",
                            "      <td>1030.000000</td>\n",
                            "      <td>1030.000000</td>\n",
                            "      <td>1030.000000</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>mean</th>\n",
                            "      <td>281.167864</td>\n",
                            "      <td>73.895825</td>\n",
                            "      <td>54.188350</td>\n",
                            "      <td>181.567282</td>\n",
                            "      <td>6.204660</td>\n",
                            "      <td>972.918932</td>\n",
                            "      <td>773.580485</td>\n",
                            "      <td>45.662136</td>\n",
                            "      <td>35.817961</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>std</th>\n",
                            "      <td>104.506364</td>\n",
                            "      <td>86.279342</td>\n",
                            "      <td>63.997004</td>\n",
                            "      <td>21.354219</td>\n",
                            "      <td>5.973841</td>\n",
                            "      <td>77.753954</td>\n",
                            "      <td>80.175980</td>\n",
                            "      <td>63.169912</td>\n",
                            "      <td>16.705742</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>min</th>\n",
                            "      <td>102.000000</td>\n",
                            "      <td>0.000000</td>\n",
                            "      <td>0.000000</td>\n",
                            "      <td>121.800000</td>\n",
                            "      <td>0.000000</td>\n",
                            "      <td>801.000000</td>\n",
                            "      <td>594.000000</td>\n",
                            "      <td>1.000000</td>\n",
                            "      <td>2.330000</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>25%</th>\n",
                            "      <td>192.375000</td>\n",
                            "      <td>0.000000</td>\n",
                            "      <td>0.000000</td>\n",
                            "      <td>164.900000</td>\n",
                            "      <td>0.000000</td>\n",
                            "      <td>932.000000</td>\n",
                            "      <td>730.950000</td>\n",
                            "      <td>7.000000</td>\n",
                            "      <td>23.710000</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>50%</th>\n",
                            "      <td>272.900000</td>\n",
                            "      <td>22.000000</td>\n",
                            "      <td>0.000000</td>\n",
                            "      <td>185.000000</td>\n",
                            "      <td>6.400000</td>\n",
                            "      <td>968.000000</td>\n",
                            "      <td>779.500000</td>\n",
                            "      <td>28.000000</td>\n",
                            "      <td>34.445000</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>75%</th>\n",
                            "      <td>350.000000</td>\n",
                            "      <td>142.950000</td>\n",
                            "      <td>118.300000</td>\n",
                            "      <td>192.000000</td>\n",
                            "      <td>10.200000</td>\n",
                            "      <td>1029.400000</td>\n",
                            "      <td>824.000000</td>\n",
                            "      <td>56.000000</td>\n",
                            "      <td>46.135000</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>max</th>\n",
                            "      <td>540.000000</td>\n",
                            "      <td>359.400000</td>\n",
                            "      <td>200.100000</td>\n",
                            "      <td>247.000000</td>\n",
                            "      <td>32.200000</td>\n",
                            "      <td>1145.000000</td>\n",
                            "      <td>992.600000</td>\n",
                            "      <td>365.000000</td>\n",
                            "      <td>82.600000</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ]
                    },
                    "metadata": {}
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Any null data to clean? (nope!)\n",
                        "Cement                0\n",
                        "Blast Furnace Slag    0\n",
                        "Fly Ash               0\n",
                        "Water                 0\n",
                        "Superplasticizer      0\n",
                        "Coarse Aggregate      0\n",
                        "Fine Aggregate        0\n",
                        "Age                   0\n",
                        "Strength              0\n",
                        "dtype: int64\n",
                        "Check predictors\n"
                    ]
                },
                {
                    "output_type": "display_data",
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>Cement</th>\n",
                            "      <th>Blast Furnace Slag</th>\n",
                            "      <th>Fly Ash</th>\n",
                            "      <th>Water</th>\n",
                            "      <th>Superplasticizer</th>\n",
                            "      <th>Coarse Aggregate</th>\n",
                            "      <th>Fine Aggregate</th>\n",
                            "      <th>Age</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>540.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>162.0</td>\n",
                            "      <td>2.5</td>\n",
                            "      <td>1040.0</td>\n",
                            "      <td>676.0</td>\n",
                            "      <td>28</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>540.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>162.0</td>\n",
                            "      <td>2.5</td>\n",
                            "      <td>1055.0</td>\n",
                            "      <td>676.0</td>\n",
                            "      <td>28</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>332.5</td>\n",
                            "      <td>142.5</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>228.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>932.0</td>\n",
                            "      <td>594.0</td>\n",
                            "      <td>270</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>332.5</td>\n",
                            "      <td>142.5</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>228.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>932.0</td>\n",
                            "      <td>594.0</td>\n",
                            "      <td>365</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>198.6</td>\n",
                            "      <td>132.4</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>192.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>978.4</td>\n",
                            "      <td>825.5</td>\n",
                            "      <td>360</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ]
                    },
                    "metadata": {}
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Check target\n",
                        "Only 1 predictor - Strength\n",
                        "Cols: 8\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Create Model"
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Normalize Data"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "source": [
                "predictors_norm = (predictors - predictors.mean()) / predictors.std()\n",
                "predictors_norm.head()\n",
                "\n",
                "n_cols = predictors_norm.shape[1] # number of predictors\n",
                "n_cols"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "8"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 4
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "source": [
                "def regressionmodel():\n",
                "    # create model\n",
                "    model = Sequential()\n",
                "    #One hidden layer of 10 nodes, and a ReLU activation function\n",
                "    model.add(Dense(10, activation='relu', input_shape=(n_cols,)))\n",
                "    model.add(Dense(1))\n",
                "    \n",
                "    #Use the adam optimizer and the mean squared error  as the loss function.\n",
                "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
                "    return model"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Randomly split the data into a training and test sets by holding 30% of the data"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "source": [
                "#Randomly split the data into a training and test sets by holding 30% of the data\n",
                "from sklearn.model_selection import train_test_split\n",
                "x_train, x_test, y_train, y_test = train_test_split(predictors_norm, target, test_size=0.3, random_state=42) #42 is the answer to life, the universe andd everything :)\n",
                "\n",
                "model = regressionmodel()\n"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "2021-08-05 12:28:22.217016: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
                        "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Train the model on the training data using 100 epochs"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "source": [
                "epochs = 100\n",
                "model.fit(x_train, y_train, epochs=epochs, verbose=1)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "2021-08-05 12:28:22.497890: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Epoch 1/100\n",
                        "23/23 [==============================] - 9s 609us/step - loss: 1608.0289\n",
                        "Epoch 2/100\n",
                        "23/23 [==============================] - 0s 669us/step - loss: 1485.2138\n",
                        "Epoch 3/100\n",
                        "23/23 [==============================] - 0s 885us/step - loss: 1486.9750\n",
                        "Epoch 4/100\n",
                        "23/23 [==============================] - 0s 805us/step - loss: 1441.4246\n",
                        "Epoch 5/100\n",
                        "23/23 [==============================] - 0s 778us/step - loss: 1501.8493\n",
                        "Epoch 6/100\n",
                        "23/23 [==============================] - 0s 867us/step - loss: 1525.2194\n",
                        "Epoch 7/100\n",
                        "23/23 [==============================] - 0s 856us/step - loss: 1477.3563\n",
                        "Epoch 8/100\n",
                        "23/23 [==============================] - 0s 838us/step - loss: 1454.6102\n",
                        "Epoch 9/100\n",
                        "23/23 [==============================] - 0s 816us/step - loss: 1385.0363\n",
                        "Epoch 10/100\n",
                        "23/23 [==============================] - 0s 791us/step - loss: 1373.9694\n",
                        "Epoch 11/100\n",
                        "23/23 [==============================] - 0s 666us/step - loss: 1370.8534\n",
                        "Epoch 12/100\n",
                        "23/23 [==============================] - 0s 584us/step - loss: 1328.4549\n",
                        "Epoch 13/100\n",
                        "23/23 [==============================] - 0s 532us/step - loss: 1344.4701\n",
                        "Epoch 14/100\n",
                        "23/23 [==============================] - 0s 529us/step - loss: 1371.8187\n",
                        "Epoch 15/100\n",
                        "23/23 [==============================] - 0s 503us/step - loss: 1232.0242\n",
                        "Epoch 16/100\n",
                        "23/23 [==============================] - 0s 550us/step - loss: 1263.8322\n",
                        "Epoch 17/100\n",
                        "23/23 [==============================] - 0s 560us/step - loss: 1249.3789\n",
                        "Epoch 18/100\n",
                        "23/23 [==============================] - 0s 547us/step - loss: 1235.4330\n",
                        "Epoch 19/100\n",
                        "23/23 [==============================] - 0s 573us/step - loss: 1197.2111\n",
                        "Epoch 20/100\n",
                        "23/23 [==============================] - 0s 565us/step - loss: 1230.9242\n",
                        "Epoch 21/100\n",
                        "23/23 [==============================] - 0s 561us/step - loss: 1155.3462\n",
                        "Epoch 22/100\n",
                        "23/23 [==============================] - 0s 572us/step - loss: 1053.2658\n",
                        "Epoch 23/100\n",
                        "23/23 [==============================] - 0s 563us/step - loss: 999.1683\n",
                        "Epoch 24/100\n",
                        "23/23 [==============================] - 0s 570us/step - loss: 956.1116\n",
                        "Epoch 25/100\n",
                        "23/23 [==============================] - 0s 550us/step - loss: 960.8849\n",
                        "Epoch 26/100\n",
                        "23/23 [==============================] - 0s 597us/step - loss: 914.0234\n",
                        "Epoch 27/100\n",
                        "23/23 [==============================] - 0s 547us/step - loss: 928.1712\n",
                        "Epoch 28/100\n",
                        "23/23 [==============================] - 0s 554us/step - loss: 806.7594\n",
                        "Epoch 29/100\n",
                        "23/23 [==============================] - 0s 541us/step - loss: 776.2148\n",
                        "Epoch 30/100\n",
                        "23/23 [==============================] - 0s 564us/step - loss: 761.9691\n",
                        "Epoch 31/100\n",
                        "23/23 [==============================] - 0s 543us/step - loss: 721.8625\n",
                        "Epoch 32/100\n",
                        "23/23 [==============================] - 0s 583us/step - loss: 673.9301\n",
                        "Epoch 33/100\n",
                        "23/23 [==============================] - 0s 550us/step - loss: 683.9314\n",
                        "Epoch 34/100\n",
                        "23/23 [==============================] - 0s 541us/step - loss: 660.8263\n",
                        "Epoch 35/100\n",
                        "23/23 [==============================] - 0s 553us/step - loss: 632.8340\n",
                        "Epoch 36/100\n",
                        "23/23 [==============================] - 0s 542us/step - loss: 560.9026\n",
                        "Epoch 37/100\n",
                        "23/23 [==============================] - 0s 575us/step - loss: 546.9383\n",
                        "Epoch 38/100\n",
                        "23/23 [==============================] - 0s 577us/step - loss: 543.4763\n",
                        "Epoch 39/100\n",
                        "23/23 [==============================] - 0s 594us/step - loss: 483.9209\n",
                        "Epoch 40/100\n",
                        "23/23 [==============================] - 0s 579us/step - loss: 463.5748\n",
                        "Epoch 41/100\n",
                        "23/23 [==============================] - 0s 583us/step - loss: 444.4774\n",
                        "Epoch 42/100\n",
                        "23/23 [==============================] - 0s 577us/step - loss: 431.4903\n",
                        "Epoch 43/100\n",
                        "23/23 [==============================] - 0s 551us/step - loss: 391.3341\n",
                        "Epoch 44/100\n",
                        "23/23 [==============================] - 0s 557us/step - loss: 374.0653\n",
                        "Epoch 45/100\n",
                        "23/23 [==============================] - 0s 554us/step - loss: 347.7751\n",
                        "Epoch 46/100\n",
                        "23/23 [==============================] - 0s 559us/step - loss: 355.8491\n",
                        "Epoch 47/100\n",
                        "23/23 [==============================] - 0s 531us/step - loss: 314.2264\n",
                        "Epoch 48/100\n",
                        "23/23 [==============================] - 0s 562us/step - loss: 309.8206\n",
                        "Epoch 49/100\n",
                        "23/23 [==============================] - 0s 549us/step - loss: 304.9945\n",
                        "Epoch 50/100\n",
                        "23/23 [==============================] - 0s 558us/step - loss: 300.4504\n",
                        "Epoch 51/100\n",
                        "23/23 [==============================] - 0s 541us/step - loss: 274.8153\n",
                        "Epoch 52/100\n",
                        "23/23 [==============================] - 0s 555us/step - loss: 267.7928\n",
                        "Epoch 53/100\n",
                        "23/23 [==============================] - 0s 545us/step - loss: 270.9494\n",
                        "Epoch 54/100\n",
                        "23/23 [==============================] - 0s 554us/step - loss: 244.9572\n",
                        "Epoch 55/100\n",
                        "23/23 [==============================] - 0s 577us/step - loss: 238.1380\n",
                        "Epoch 56/100\n",
                        "23/23 [==============================] - 0s 569us/step - loss: 243.3253\n",
                        "Epoch 57/100\n",
                        "23/23 [==============================] - 0s 556us/step - loss: 242.4762\n",
                        "Epoch 58/100\n",
                        "23/23 [==============================] - 0s 551us/step - loss: 231.6859\n",
                        "Epoch 59/100\n",
                        "23/23 [==============================] - 0s 627us/step - loss: 239.1256\n",
                        "Epoch 60/100\n",
                        "23/23 [==============================] - 0s 586us/step - loss: 213.4892\n",
                        "Epoch 61/100\n",
                        "23/23 [==============================] - 0s 572us/step - loss: 215.9847\n",
                        "Epoch 62/100\n",
                        "23/23 [==============================] - 0s 658us/step - loss: 201.6039\n",
                        "Epoch 63/100\n",
                        "23/23 [==============================] - 0s 819us/step - loss: 202.0219\n",
                        "Epoch 64/100\n",
                        "23/23 [==============================] - 0s 727us/step - loss: 201.0036\n",
                        "Epoch 65/100\n",
                        "23/23 [==============================] - 0s 798us/step - loss: 196.8648\n",
                        "Epoch 66/100\n",
                        "23/23 [==============================] - 0s 894us/step - loss: 197.9850\n",
                        "Epoch 67/100\n",
                        "23/23 [==============================] - 0s 887us/step - loss: 189.2674\n",
                        "Epoch 68/100\n",
                        "23/23 [==============================] - 0s 871us/step - loss: 193.6586\n",
                        "Epoch 69/100\n",
                        "23/23 [==============================] - 0s 845us/step - loss: 192.8318\n",
                        "Epoch 70/100\n",
                        "23/23 [==============================] - 0s 911us/step - loss: 200.3618\n",
                        "Epoch 71/100\n",
                        "23/23 [==============================] - 0s 955us/step - loss: 192.3332\n",
                        "Epoch 72/100\n",
                        "23/23 [==============================] - 0s 849us/step - loss: 193.1421\n",
                        "Epoch 73/100\n",
                        "23/23 [==============================] - 0s 828us/step - loss: 193.2260\n",
                        "Epoch 74/100\n",
                        "23/23 [==============================] - 0s 839us/step - loss: 188.4832\n",
                        "Epoch 75/100\n",
                        "23/23 [==============================] - 0s 769us/step - loss: 188.3718\n",
                        "Epoch 76/100\n",
                        "23/23 [==============================] - 0s 770us/step - loss: 190.2518\n",
                        "Epoch 77/100\n",
                        "23/23 [==============================] - 0s 728us/step - loss: 166.4655\n",
                        "Epoch 78/100\n",
                        "23/23 [==============================] - 0s 681us/step - loss: 179.9730\n",
                        "Epoch 79/100\n",
                        "23/23 [==============================] - 0s 562us/step - loss: 181.8180\n",
                        "Epoch 80/100\n",
                        "23/23 [==============================] - 0s 529us/step - loss: 167.2638\n",
                        "Epoch 81/100\n",
                        "23/23 [==============================] - 0s 555us/step - loss: 177.4234\n",
                        "Epoch 82/100\n",
                        "23/23 [==============================] - 0s 567us/step - loss: 167.3736\n",
                        "Epoch 83/100\n",
                        "23/23 [==============================] - 0s 564us/step - loss: 179.2284\n",
                        "Epoch 84/100\n",
                        "23/23 [==============================] - 0s 565us/step - loss: 173.4609\n",
                        "Epoch 85/100\n",
                        "23/23 [==============================] - 0s 574us/step - loss: 172.8304\n",
                        "Epoch 86/100\n",
                        "23/23 [==============================] - 0s 565us/step - loss: 181.2120\n",
                        "Epoch 87/100\n",
                        "23/23 [==============================] - 0s 542us/step - loss: 173.7126\n",
                        "Epoch 88/100\n",
                        "23/23 [==============================] - 0s 593us/step - loss: 169.0629\n",
                        "Epoch 89/100\n",
                        "23/23 [==============================] - 0s 559us/step - loss: 174.7644\n",
                        "Epoch 90/100\n",
                        "23/23 [==============================] - 0s 612us/step - loss: 160.1774\n",
                        "Epoch 91/100\n",
                        "23/23 [==============================] - 0s 641us/step - loss: 166.7989\n",
                        "Epoch 92/100\n",
                        "23/23 [==============================] - 0s 609us/step - loss: 164.2985\n",
                        "Epoch 93/100\n",
                        "23/23 [==============================] - 0s 708us/step - loss: 169.1799\n",
                        "Epoch 94/100\n",
                        "23/23 [==============================] - 0s 686us/step - loss: 161.2852\n",
                        "Epoch 95/100\n",
                        "23/23 [==============================] - 0s 700us/step - loss: 155.1299\n",
                        "Epoch 96/100\n",
                        "23/23 [==============================] - 0s 786us/step - loss: 167.6354\n",
                        "Epoch 97/100\n",
                        "23/23 [==============================] - 0s 804us/step - loss: 155.6722\n",
                        "Epoch 98/100\n",
                        "23/23 [==============================] - 0s 737us/step - loss: 173.4767\n",
                        "Epoch 99/100\n",
                        "23/23 [==============================] - 0s 817us/step - loss: 161.2781\n",
                        "Epoch 100/100\n",
                        "23/23 [==============================] - 0s 827us/step - loss: 150.8195\n"
                    ]
                },
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "<keras.callbacks.History at 0x19813e820>"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 7
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Eval the model"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "source": [
                "#eval our model\n",
                "\n",
                "loss_val = model.evaluate(x_test, y_test)\n",
                "y_pred = model.predict(x_test)\n",
                "print (loss_val)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "10/10 [==============================] - 0s 761us/step - loss: 159.5498\n",
                        "159.54983520507812\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Calc the Mean, Std Dev"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "source": [
                "mean_square_error = mean_squared_error(y_test, y_pred)\n",
                "mean = np.mean(mean_square_error)\n",
                "standard_deviation = np.std(mean_square_error)\n",
                "print(\"Mean: \" + str(mean))\n",
                "print (\"Std Dev: \" + str(standard_deviation))"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Mean: 159.54983755472819\n",
                        "Std Dev: 0.0\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Final Results"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "source": [
                "\n",
                "epochs = 100\n",
                "mean_squared_errors = []\n",
                "for i in range(0, 50):\n",
                "    x_train, x_test, y_train, y_test = train_test_split(predictors_norm, target, test_size=0.3, random_state=i)\n",
                "    model.fit(x_train, y_train, epochs=epochs, verbose=0)\n",
                "    meansqerr = model.evaluate(x_test, y_test, verbose=0)\n",
                "    print(\"(\" + str (i+1) + \") - Mean Squared Error : \" + str(meansqerr))\n",
                "    y_pred = model.predict(x_test)\n",
                "    mean_square_error = mean_squared_error(y_test, y_pred)\n",
                "    mean_squared_errors.append(mean_square_error)\n",
                "\n",
                "mean_squared_errors = np.array(mean_squared_errors)\n",
                "mean = np.mean(mean_squared_errors)\n",
                "std_dev = np.std(mean_squared_errors)\n",
                "\n",
                "\n",
                "print(\"Mean, Standard deviation of 50 mse with normalized data. Total epochs for each training is: \" + str(epochs))\n",
                "print(\"Mean: \" + str(mean))\n",
                "print(\"Standard Deviation: \" +  str(std_dev))"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "(1) - Mean Squared Error : 35.616153717041016\n",
                        "(2) - Mean Squared Error : 43.42072677612305\n",
                        "(3) - Mean Squared Error : 33.65302658081055\n",
                        "(4) - Mean Squared Error : 38.03367614746094\n",
                        "(5) - Mean Squared Error : 40.69731140136719\n",
                        "(6) - Mean Squared Error : 41.31132125854492\n",
                        "(7) - Mean Squared Error : 44.8650016784668\n",
                        "(8) - Mean Squared Error : 36.13899230957031\n",
                        "(9) - Mean Squared Error : 37.6478385925293\n",
                        "(10) - Mean Squared Error : 35.53895568847656\n",
                        "(11) - Mean Squared Error : 37.769222259521484\n",
                        "(12) - Mean Squared Error : 33.48060607910156\n",
                        "(13) - Mean Squared Error : 41.182518005371094\n",
                        "(14) - Mean Squared Error : 45.36955642700195\n",
                        "(15) - Mean Squared Error : 34.45039749145508\n",
                        "(16) - Mean Squared Error : 33.936119079589844\n",
                        "(17) - Mean Squared Error : 37.32569122314453\n",
                        "(18) - Mean Squared Error : 36.870609283447266\n",
                        "(19) - Mean Squared Error : 35.92274475097656\n",
                        "(20) - Mean Squared Error : 39.33665466308594\n",
                        "(21) - Mean Squared Error : 37.13453674316406\n",
                        "(22) - Mean Squared Error : 38.34831619262695\n",
                        "(23) - Mean Squared Error : 32.7172737121582\n",
                        "(24) - Mean Squared Error : 38.240631103515625\n",
                        "(25) - Mean Squared Error : 37.32304382324219\n",
                        "(26) - Mean Squared Error : 40.037967681884766\n",
                        "(27) - Mean Squared Error : 34.709835052490234\n",
                        "(28) - Mean Squared Error : 32.68912124633789\n",
                        "(29) - Mean Squared Error : 39.78322982788086\n",
                        "(30) - Mean Squared Error : 40.005130767822266\n",
                        "(31) - Mean Squared Error : 37.15289306640625\n",
                        "(32) - Mean Squared Error : 33.06735610961914\n",
                        "(33) - Mean Squared Error : 34.84053421020508\n",
                        "(34) - Mean Squared Error : 36.85249710083008\n",
                        "(35) - Mean Squared Error : 36.21723175048828\n",
                        "(36) - Mean Squared Error : 41.56650924682617\n",
                        "(37) - Mean Squared Error : 37.22820281982422\n",
                        "(38) - Mean Squared Error : 40.23637390136719\n",
                        "(39) - Mean Squared Error : 38.27602005004883\n",
                        "(40) - Mean Squared Error : 32.663536071777344\n",
                        "(41) - Mean Squared Error : 40.97774124145508\n",
                        "(42) - Mean Squared Error : 34.839027404785156\n",
                        "(43) - Mean Squared Error : 35.76353454589844\n",
                        "(44) - Mean Squared Error : 43.316349029541016\n",
                        "(45) - Mean Squared Error : 44.05339431762695\n",
                        "(46) - Mean Squared Error : 40.981964111328125\n",
                        "(47) - Mean Squared Error : 37.44225311279297\n",
                        "(48) - Mean Squared Error : 37.00749206542969\n",
                        "(49) - Mean Squared Error : 42.066341400146484\n",
                        "(50) - Mean Squared Error : 38.61518859863281\n",
                        "Mean, Standard deviation of 50 mse with normalized data. Total epochs for each training is: 100\n",
                        "Mean: 37.93441318292599\n",
                        "Standard Deviation: 3.263647997165232\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## How does the mean of the mean squared errors compare to that from Step B?"
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "Mean has increased slightly"
            ],
            "metadata": {}
        }
    ],
    "metadata": {
        "orig_nbformat": 4,
        "language_info": {
            "name": "python",
            "version": "3.9.6",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.9.6 64-bit"
        },
        "interpreter": {
            "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}